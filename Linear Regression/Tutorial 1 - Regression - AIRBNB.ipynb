{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1 - Regression\n",
    "\n",
    "We will predict the price (`price` column) of an AirBNB listing in Boston given a number of features about the listing.\n",
    "\n",
    "**Therefore, our unit of analysis is an AIRBNB LISTING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will predict the \"price\" value in the data set:\n",
    "\n",
    "airbnb = pd.read_csv(\"airbnb.csv\")\n",
    "airbnb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(airbnb, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be careful: we haven't seperated the target column yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the variables we can't use in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't use the following columns in this tutorial, because they are for classification tasks\n",
    "\n",
    "train = train_set.drop(['price_gte_150', 'price_category'], axis=1)\n",
    "test = test_set.drop(['price_gte_150', 'price_category'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the target variable (we don't want to transform it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train[['price']]\n",
    "test_y = test[['price']]\n",
    "\n",
    "train_inputs = train.drop(['price'], axis=1)\n",
    "test_inputs = test.drop(['price'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Identify the numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this stage, you can manually identify numeric, binary, and categorical columns as follows:**\n",
    "\n",
    "`numeric_columns = ['latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'Number of amenities', 'guests_included', 'price_per_extra_person', 'minimum_nights', 'number_of_reviews', 'number_days_btw_first_last_review', 'review_scores_rating']`\n",
    " \n",
    " `binary_columns = ['host_is_superhost', 'host_identity_verified']`\n",
    " \n",
    " `categorical_columns = ['neighbourhood_cleansed', 'property_type', 'room_type', 'bed_type', 'cancellation_policy']`\n",
    " \n",
    "<br>\n",
    " \n",
    "**If you do not want to manually type these, you can do the below tricks:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numerical columns\n",
    "numeric_columns = train_inputs.select_dtypes(include=[np.number]).columns.to_list()\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns = train_inputs.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the binary columns so we can pass them through without transforming\n",
    "binary_columns = ['host_is_superhost', 'host_identity_verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful: numerical columns already includes the binary columns,\n",
    "# So, we need to remove the binary columns from numerical columns.\n",
    "\n",
    "for col in binary_columns:\n",
    "    numeric_columns.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='mean')),\n",
    "                ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns),\n",
    "        ('binary', binary_transformer, binary_columns)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "#passtrough is an optional step. You don't have to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform: fit_transform() for TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit and transform the train data\n",
    "train_x = preprocessor.fit_transform(train_inputs)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranform: transform() for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data\n",
    "test_x = preprocessor.transform(test_inputs)\n",
    "\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closed form solution\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "lin_reg.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = lin_reg.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error (train_y, reg_train_pred))\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = lin_reg.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error (test_y, reg_test_pred))\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First find the average value of the target\n",
    "\n",
    "mean_value = np.mean(train_y['price'])\n",
    "\n",
    "mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict all values as the mean\n",
    "\n",
    "baseline_pred = np.repeat(mean_value, len(test_y))\n",
    "\n",
    "baseline_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mse = mean_squared_error(test_y, baseline_pred)\n",
    "\n",
    "baseline_rmse = np.sqrt(baseline_mse)\n",
    "\n",
    "print('Baseline RMSE: {}' .format(baseline_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Stochastic Gradient Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor \n",
    "\n",
    "# tol = stopping criterion\n",
    "# eta0 = learning rate\n",
    "# penalty = regularization term\n",
    "# max_iter = number of passes over training data (i.e., epochs)\n",
    "\n",
    "sgd_reg = SGDRegressor(max_iter=100, penalty=None, eta0=0.1, tol=0.0001) \n",
    "\n",
    "sgd_reg.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = sgd_reg.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error (train_y, reg_train_pred))\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = sgd_reg.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error (test_y, reg_test_pred))\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression\n",
    "\n",
    "This is done by creating the polynomial \"variables\" of the existing variables, then fitting them in a regular regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create second degree terms and interaction terms\n",
    "poly_features = PolynomialFeatures(degree=2).fit(train_x)\n",
    "\n",
    "train_x_poly = poly_features.transform(train_x)\n",
    "\n",
    "test_x_poly = poly_features.transform(test_x)\n",
    "\n",
    "#Mind you, this will create the polynomial terms of the categorical variables too\n",
    "\n",
    "#if degree=3, then it creates all combinations: a, a^2, a^3, b, b^2, b^3, a.b, a^2.b, a.b^2, a^2.b^2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We still fit a linear regression model\n",
    "\n",
    "pol_lin_reg = LinearRegression()\n",
    "\n",
    "pol_lin_reg.fit(train_x_poly, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = pol_lin_reg.predict(train_x_poly)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error (train_y, reg_train_pred))\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = pol_lin_reg.predict(test_x_poly)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error (test_y, reg_test_pred))\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closed form solution:\n",
    "# Remember, alpha is the magnitude of regularization\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_reg = Ridge(alpha=0.1, solver='cholesky')\n",
    "\n",
    "ridge_reg.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = ridge_reg.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error (train_y, reg_train_pred))\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = ridge_reg.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error (test_y, reg_test_pred))\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient:\n",
    "\n",
    "sgd_reg_L2 = SGDRegressor(max_iter=50, penalty='l2', alpha = 0.1, eta0=0.1, tol=0.0001)\n",
    "\n",
    "sgd_reg_L2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = sgd_reg_L2.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error (train_y, reg_train_pred))\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = sgd_reg_L2.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error (test_y, reg_test_pred))\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closed form solution:\n",
    "# Remember, alpha is the magnitude of regularization\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_reg = Lasso(alpha=0.1, max_iter=100000)\n",
    "\n",
    "lasso_reg.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = lasso_reg.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error (train_y, reg_train_pred))\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = lasso_reg.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error (test_y, reg_test_pred))\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient:\n",
    "sgd_reg_L1 = SGDRegressor(max_iter=50, penalty='l1', alpha = 0.1, eta0=0.1, tol=0.0001)\n",
    "\n",
    "sgd_reg_L1.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = sgd_reg_L1.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error (train_y, reg_train_pred))\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = sgd_reg_L1.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error (test_y, reg_test_pred))\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember, alpha is the magnitude of regularization\n",
    "# And, l1_ratio is how much L1 vs. L2 regularization to do.\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "\n",
    "elastic_net.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = elastic_net.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error (train_y, reg_train_pred))\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = elastic_net.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error (test_y, reg_test_pred))\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient:\n",
    "sgd_reg_elastic = SGDRegressor(max_iter=50, penalty='elasticnet', l1_ratio=0.5, alpha = 0.1, \n",
    "                          eta0=0.1, tol=0.0001)\n",
    "sgd_reg_elastic.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = sgd_reg_elastic.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error (train_y, reg_train_pred))\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = sgd_reg_elastic.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error (test_y, reg_test_pred))\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "sgd_reg_ES = SGDRegressor(max_iter=500, early_stopping = True, n_iter_no_change=5, \n",
    "                          validation_fraction=0.2,\n",
    "                          eta0=0.01, tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg_ES.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of iterations with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd_reg_ES.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = sgd_reg_ES.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error (train_y, reg_train_pred))\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = sgd_reg_ES.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error (test_y, reg_test_pred))\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of iterations without early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "sgd_reg_ES = SGDRegressor(max_iter=500, eta0=0.01, tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg_ES.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd_reg_ES.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = sgd_reg_ES.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error (train_y, reg_train_pred))\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = sgd_reg_ES.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error (test_y, reg_test_pred))\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember: Polynomial model has severe overfitting. Perfom regualization on it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember, alpha is the magnitude of regularization\n",
    "# And, l1_ratio is how much L1 vs. L2 regularization to do.\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_net = ElasticNet(alpha=0.05, l1_ratio=0.5)\n",
    "\n",
    "elastic_net.fit(train_x_poly, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = elastic_net.predict(train_x_poly)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error (train_y, reg_train_pred))\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = elastic_net.predict(test_x_poly)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error (test_y, reg_test_pred))\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
